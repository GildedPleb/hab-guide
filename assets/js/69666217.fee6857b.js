"use strict";(self.webpackChunkhab_guide=self.webpackChunkhab_guide||[]).push([[6737],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>m});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},s=Object.keys(e);for(a=0;a<s.length;a++)n=s[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(a=0;a<s.length;a++)n=s[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var r=a.createContext({}),u=function(e){var t=a.useContext(r),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},d=function(e){var t=u(e.components);return a.createElement(r.Provider,{value:t},e.children)},h="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,s=e.originalType,r=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),h=u(n),c=i,m=h["".concat(r,".").concat(c)]||h[c]||p[c]||s;return n?a.createElement(m,o(o({ref:t},d),{},{components:n})):a.createElement(m,o({ref:t},d))}));function m(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var s=n.length,o=new Array(s);o[0]=c;var l={};for(var r in t)hasOwnProperty.call(t,r)&&(l[r]=t[r]);l.originalType=e,l[h]="string"==typeof e?e:i,o[1]=l;for(var u=2;u<s;u++)o[u]=n[u];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},8259:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>r,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>l,toc:()=>u});var a=n(7462),i=(n(7294),n(3905));const s={sidebar_position:4},o="Stand-up Live",l={unversionedId:"l2-k3s/standup-live",id:"l2-k3s/standup-live",title:"Stand-up Live",description:"Let's now stand-up a live k3s cluster.",source:"@site/docs/l2-k3s/standup-live.md",sourceDirName:"l2-k3s",slug:"/l2-k3s/standup-live",permalink:"/hab-guide/docs/l2-k3s/standup-live",draft:!1,editUrl:"https://github.com/GildedPleb/hab-guide/edit/master/website/docs/l2-k3s/standup-live.md",tags:[],version:"current",lastUpdatedBy:"GildedPleb",lastUpdatedAt:1672878126,formattedLastUpdatedAt:"Jan 5, 2023",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Tear-down Vanilla",permalink:"/hab-guide/docs/l2-k3s/teardown-vanilla"},next:{title:"Tear-down Live",permalink:"/hab-guide/docs/l2-k3s/teardown-live"}},r={},u=[{value:"Live K3s",id:"live-k3s",level:2},{value:"Editing The Live Settings",id:"editing-the-live-settings",level:3},{value:"System-Upgrade-Controller",id:"system-upgrade-controller",level:3},{value:"MetalLB",id:"metallb",level:3},{value:"NGINX",id:"nginx",level:3},{value:"Cert-Manager",id:"cert-manager",level:3},{value:"Longhorn",id:"longhorn",level:3},{value:"Stand-up Live K3s",id:"stand-up-live-k3s",level:2}],d={toc:u};function h(e){let{components:t,...n}=e;return(0,i.kt)("wrapper",(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"stand-up-live"},"Stand-up Live"),(0,i.kt)("p",null,"Let's now stand-up a live k3s cluster."),(0,i.kt)("p",null,'Though k3s is fully live and active in its "vanilla state" we can\'t build\nanything substantial on top of it without first running some "service apps" that\nopen up its functionality layers. All these apps will be required to get Bitcoin\nin the proper environment. As such, completing these steps will be getting\nBitcoin not just into the raw state, but into the vanilla state as well. As\nmentioned, once we lean deeper into the software side of things, we start to get\nvery streamlined.'),(0,i.kt)("h2",{id:"live-k3s"},"Live K3s"),(0,i.kt)("p",null,"All of these apps can be installed with one Ansible-Playbook command, which we\nwill do at the end, but we will need to edit more than a few settings\nbeforehand. Though pre-sets exist, you should tinker, try to get your barrings,\nand change a handful of things. We will try to point out all the needed changes\nand offer basic explanations."),(0,i.kt)("admonition",{type:"caution"},(0,i.kt)("p",{parentName:"admonition"},(0,i.kt)("inlineCode",{parentName:"p"},"yml")," is a language that is dependent on white space\u2014this means that the number\nof spaces before each line of text matter. If you are opening up the playbook in\na text editor, be sure to turn off all non-yml auto-formatting, as it may\ndestroy the file. Or use a code editor built to purpose which is how you should\ndo it anyway, for instance, VS Code.")),(0,i.kt)("h3",{id:"editing-the-live-settings"},"Editing The Live Settings"),(0,i.kt)("p",null,"Before you do any editing, in a text editor, open up the file\n",(0,i.kt)("inlineCode",{parentName:"p"},"K3s/standup-live.yml"),". It will be the playbook that we run, and the next few\nsections here will follow along with it. In particular, you should pay attention\nto the following ",(0,i.kt)("inlineCode",{parentName:"p"},"include_tasks"),", and how those included tasks point to the\n",(0,i.kt)("inlineCode",{parentName:"p"},"K3s/charts/")," directory."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="hab-plays/K3s/standup-live.yml"',title:'"hab-plays/K3s/standup-live.yml"'},"...\n    # Install k3s automated upgrades\n    - include_tasks: tasks/system-upgrade-controller.yml\n\n    # Add and Install MetalLB\n    - include_tasks: tasks/metalLB.yml\n\n    # Add and Install nginx\n    - include_tasks: tasks/nginx.yml\n\n...\n\n    # Add and Install Cert Manager\n    - include_tasks: tasks/cert-manager.yml\n\n    # Add and Install Longhorn\n    - include_tasks: tasks/longhorn.yml\n...\n")),(0,i.kt)("p",null,"By and large, we will be editing settings that are in ",(0,i.kt)("inlineCode",{parentName:"p"},"K3s/charts/"),", as such, we\nwill be editing definitions for Kubernetes resources, and not Ansible tasks."),(0,i.kt)("p",null,"So, lets jump into the actual applications."),(0,i.kt)("h3",{id:"system-upgrade-controller"},"System-Upgrade-Controller"),(0,i.kt)("p",null,'The system upgrade controller automates the process of updating the k3s version\non each node. Essentially, when SUC (great name...) sees that a new version of\nk3s is available, it sections off one host ("cordons"), updates it, and then\nreturns it to the pool of hosts ("uncordons"). It first does this for masters\nand then for workers. In effect, you can think of ',(0,i.kt)("em",{parentName:"p"},"this entire upgrade app")," as\nbeing declared by the file Ansible downloads and these blocks of ",(0,i.kt)("inlineCode",{parentName:"p"},"yml"),"."),(0,i.kt)("p",null,"You should be able to see that it uses ",(0,i.kt)("inlineCode",{parentName:"p"},"concurrency: 1")," to cordon 1 host at a\ntime while it updates. The defaults should suffice for all, but do consult the\n",(0,i.kt)("a",{parentName:"p",href:"https://rancher.com/docs/k3s/latest/en/upgrades/automated/"},"docs")," first if you\nwould like to make changes."),(0,i.kt)("p",null,"To change the SUC settings, edit these files before installing:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"strong"},"K3s/charts/SUC/plan-agent.yml"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"strong"},"K3s/charts/SUC/plan-server.yml")))),(0,i.kt)("admonition",{title:"Cordoning may be expencive",type:"caution"},(0,i.kt)("p",{parentName:"admonition"},"If you plan on running a node where resources are regularly maxed out, and/or if\nyour steady-state HAB node does not have N+1 available space, you may be\ncounting down days till downtime with a SUC installed. But, many will not have\naccess to 4 computers to do this anyway, so if that is you, you might consider\ncommenting out this upgrading code in ",(0,i.kt)("inlineCode",{parentName:"p"},"K3s/standup-live.yml")," so that it is not\ndeployed on your cluster."),(0,i.kt)("pre",{parentName:"admonition"},(0,i.kt)("code",{parentName:"pre",className:"language-yml"},"# Install k3s automated upgrades\n# - include_tasks: tasks/system-upgrade-controller.yml\n")),(0,i.kt)("p",{parentName:"admonition"},"This also means you will have to upgrade your cluster manually.")),(0,i.kt)("h3",{id:"metallb"},"MetalLB"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://metallb.universe.tf/"},"MetalLB")," is a load balancer which opens up your\nk3s cluster to its wider network: it gives the services on your node IP\naddresses. Don't worry, none of this is public if your LAN subnet is not public\nand behind a firewall like pfSense. There are a few load balancers in the k8s\nuniverse, but this one is a basic one for bare metal, and self-hosting, which,\nat the time of research in March 2022, many load balancers did not offer (but\napparently, in Dec 2022, there are others now). Remember that Kubernetes is\n",(0,i.kt)("em",{parentName:"p"},"cloud")," native, not ",(0,i.kt)("em",{parentName:"p"},"edge")," native, but it does work wonders at the edge!"),(0,i.kt)("p",null,"Be sure to edit the IP range so that it reflect a range that will be available\nfrom your router. If you recall, for us,\n",(0,i.kt)("a",{parentName:"p",href:"/docs/l1-hosts/networking#designate-ip-address-block"},"that was set to"),"\n",(0,i.kt)("inlineCode",{parentName:"p"},"10.1.0.50-99"),"."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yml",metastring:'title="hab-plays/K3s/charts/Metallb"',title:'"hab-plays/K3s/charts/Metallb"'},"configInline:\naddress-pools:\n    - name: default\n    protocol: layer2\n    addresses:\n        - 10.1.0.50-10.1.0.99    #<<--- HERE\n")),(0,i.kt)("p",null,"This is the first block to use Helm, as you will have undoubtedly noticed from\nthe lines ",(0,i.kt)("inlineCode",{parentName:"p"},"kubernetes.core.helm_repository")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"kubernetes.core.helm:")," in\n",(0,i.kt)("inlineCode",{parentName:"p"},"hab-plays/K3s/tasks/metalLB.yml"),". The equivalent commands for this Ansible\nblock are:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"helm repo add metallb https://metallb.github.io/metallb\nhelm install metallb metallb/metallb -n kube-system -f K3s/charts/MetalLB/values.yml\n")),(0,i.kt)("p",null,'If you run these commands, and also run them in the Ansible script, guess what?\nNothing should happen! Ansible is declarative, Helm is declarative, and\nKubernetes is declarative. All of these systems are given instructions like\n"Hey, we want this software to be defined as such", and if the software is\nalready defined as such, it says, "Looks great!" and does nothing.'),(0,i.kt)("h3",{id:"nginx"},"NGINX"),(0,i.kt)("p",null,'Nginx (pronounced "Engine-X") is an ingress, it takes traffic which is coming in\nand says "Ah! I know what to do with this ',(0,i.kt)("inlineCode",{parentName:"p"},"web request"),'". More\n',(0,i.kt)("a",{parentName:"p",href:"https://kubernetes.github.io/ingress-nginx/"},"here"),". You will need this ingress\nto handle potentially many things in the cluster, most notably is the Longhorn\nUI."),(0,i.kt)("p",null,"There are no settings to change for this one."),(0,i.kt)("p",null,"Once the ingress controller has been installed, Ansible will wait for the\nLoadBalancer IP to be available. You can watch the status by running the\nfollowing command in another terminal window, before standing up live k8s:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl ns kube-system\nwatch kubectl get services\n")),(0,i.kt)("p",null,"By the time the Ansible command is finished, you should see something like:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"% kubectl get services\nNAME                                       TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)                      AGE\nkube-dns                                   ClusterIP      10.43.0.10     <none>        53/UDP,53/TCP,9153/TCP       50m\nmetrics-server                             ClusterIP      10.43.53.37    <none>        443/TCP                      50m\nnginx-ingress-nginx-controller             LoadBalancer   10.43.92.27    10.1.0.50     80:31559/TCP,443:31850/TCP   43m\nnginx-ingress-nginx-controller-admission   ClusterIP      10.43.90.232   <none>        443/TCP                      43m\n")),(0,i.kt)("p",null,"Finally, to make sure it is indeed working, open a web browser on your control\ncomputer and point it to the ",(0,i.kt)("inlineCode",{parentName:"p"},"nginx-ingress-nginx-controller")," ",(0,i.kt)("inlineCode",{parentName:"p"},"EXTERNAL-IP"),"\n(e.g. 10.1.0.50 in the example above) and you should see the infamous"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"        404 Not Found\n-------------------------------\n            nginx\n")),(0,i.kt)("p",null,"This means it's working\u2014that your web traffic is making it to your cluster\u2014but\nthat your cluster has nothing to serve, which is expected. Insert failed\nsuccessfully memes."),(0,i.kt)("h3",{id:"cert-manager"},"Cert-Manager"),(0,i.kt)("p",null,"The ",(0,i.kt)("a",{parentName:"p",href:"https://cert-manager.io/v0.14-docs/installation/kubernetes/"},"Cert Manager"),"\nallows your cluster to automatically issue, request, and sign certificates to\nencrypt communications."),(0,i.kt)("p",null,"There are no settings to change for this one either."),(0,i.kt)("p",null,"We are automatically adding self-signing certs to the manager, so you can deploy\nservices privately. It is out of the scope of this guide to create a public\ninterface, though it's perfectly feasible once you have a Cert Manager!"),(0,i.kt)("p",null,"To ensure that it is installed and working correctly, in the ",(0,i.kt)("inlineCode",{parentName:"p"},"cert-manager"),"\nnamespace you should see three running pods. If you wanted, you could open yet\nanother terminal window and ",(0,i.kt)("inlineCode",{parentName:"p"},"watch")," them get populated with the command, (It\nwill be important to ",(0,i.kt)("em",{parentName:"p"},"not")," set the namespace with ",(0,i.kt)("inlineCode",{parentName:"p"},"ns")," for this, as that will\nalter the other ",(0,i.kt)("inlineCode",{parentName:"p"},"watch")," command, if you are also running that):"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"watch kubectl get pod -n cert-manager\n")),(0,i.kt)("p",null,"Otherwise, after the Ansible command has run, confirm it's good to go by\nrunning:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'% kubectl ns cert-manager\nContext "default" modified.\nActive namespace is "cert-manager".\n% kubectl get pod\nNAME                                     READY   STATUS    RESTARTS   AGE\ncert-manager-76d44b459c-hntxp            1/1     Running   0          115m\ncert-manager-cainjector-9b679cc6-n8jpv   1/1     Running   0          115m\ncert-manager-webhook-57c994b6b9-tkfc9    1/1     Running   0          115m\n')),(0,i.kt)("p",null,"Above, you should see three healthy pods: ",(0,i.kt)("inlineCode",{parentName:"p"},"cert-manager"),",\n",(0,i.kt)("inlineCode",{parentName:"p"},"cert-manager-cainjector"),", and ",(0,i.kt)("inlineCode",{parentName:"p"},"cert-manager-webhook"),"."),(0,i.kt)("h3",{id:"longhorn"},"Longhorn"),(0,i.kt)("p",null,"Alright, now it's time for the big guy: Longhorn."),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://longhorn.io/"},"Longhorn")," is a highly available persistent storage\nsolution for Kubernetes. It makes managing blockchain data sane. But it's also\nnot without its downsides and added complications. For now, we still think its\nworth including in the cluster as it will allow us to easily monitor storage,\nbackup data, and provide replication. Plus, it's a straightforward and useful\nprimer to seeing just how vastly powerful this cluster can become."),(0,i.kt)("p",null,"First, Ansible will be running\n",(0,i.kt)("a",{parentName:"p",href:"https://longhorn.io/docs/1.3.2/deploy/install/#using-the-environment-check-script"},"this script"),"\non the local machine which will use ",(0,i.kt)("inlineCode",{parentName:"p"},"kubectl")," to spin up pods on each host to\nmake sure everything meets minimum requirements and was installed correctly."),(0,i.kt)("p",null,"Then, Ansible will run a version of the commands found\n",(0,i.kt)("a",{parentName:"p",href:"https://longhorn.io/docs/1.3.2/deploy/install/install-with-helm/"},"here")," and\n",(0,i.kt)("a",{parentName:"p",href:"https://longhorn.io/docs/1.3.2/deploy/accessing-the-ui/longhorn-ingress/"},"here"),"\nbut will run it in a way as to save secrets safely. Most of the Ansible script\nherein, will be better understood by also reading these links. Ansible will add\na secret for volume encryption, which can be found in the Ansible vault at\n",(0,i.kt)("inlineCode",{parentName:"p"},"~/.HAB/vault-lh-encryption-token"),", and it will save the authentication password\nto ",(0,i.kt)("inlineCode",{parentName:"p"},"~/.HAB/vault-lh-auth-token"),"."),(0,i.kt)("p",null,"Take note that Ansible installs an ingress, and a certificate. Can you guess\nwhat web-traffic directing and encrypting might get you? Access to an\nin-browsers user interface for your HAB node storage!"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"The Longhorn UI")),(0,i.kt)("p",null,"To get access to this UI you will need to edit a few lines to meet your needs.\nBelow we have taken care to try and explain all the lines in the ingress, as it\nis perhaps one of the more opaque parts of this entire process."),(0,i.kt)("p",null,"Take a deep breath. The only parts you need to edit are the ",(0,i.kt)("strong",{parentName:"p"},"three")," locations\nof ",(0,i.kt)("inlineCode",{parentName:"p"},"lh.gilded.lan"),". And you don't even need to edit those if you don't want to.\nIf you do decide to edit them, ",(0,i.kt)("em",{parentName:"p"},"they must be the same"),", and they ",(0,i.kt)("em",{parentName:"p"},"must match"),"\nthe following longhorn cert. Also, make sure it has a unique sub-domain, domain,\nand top-level-domain that remains local (like ",(0,i.kt)("inlineCode",{parentName:"p"},".lan"),")."),(0,i.kt)("p",null,"Here is the annotated Longhorn Ingress and Cert:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yml",metastring:'title="hab-plays/K3s/charts/longhorn/ingress.yml"',title:'"hab-plays/K3s/charts/longhorn/ingress.yml"'},"# Version that this resource definition applies to\napiVersion: networking.k8s.io/v1\n# Kind of resource definition that this is\nkind: Ingress\n# The data needed to define the resource for outside services and managers looking in\nmetadata:\n  name: longhorn-ingress\n  namespace: longhorn-system\n  annotations:\n    kubernetes.io/ingress.class: 'nginx' # Use the nginx ingress we previously defined.\n    # type of authentication\n    nginx.ingress.kubernetes.io/auth-type: basic # A pop-up window asking for a user name and password\n    # prevent the controller from redirecting (308) to HTTPS\n    # nginx.ingress.kubernetes.io/ssl-redirect: 'false'\n    cert-manager.io/cluster-issuer: 'selfsigned-issuer' # Encrypt using the ClusterIssuer deployed while setting up Cert-Manager\n    # name of the secret that contains the user/password definitions, this is defined in the longhorn Ansible script, search for \"basic-auth\"\n    nginx.ingress.kubernetes.io/auth-secret: basic-auth\n    # message to display with an appropriate context why the authentication is required\n    nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required'\n    # custom max body size for file uploading like backing image uploading\n    nginx.ingress.kubernetes.io/proxy-body-size: 10000m\n# The specification of the resource internally\nspec:\n  rules:\n    - host: lh.gilded.lan # the location of the host\n      http:\n        paths:\n          - pathType: Prefix\n            path: '/'\n            backend:\n              service:\n                name: longhorn-frontend # this is a service defined by Longhorn. It is where, 'lh.gilded.lan' will point to, it is the UI.\n                port:\n                  number: 80\n    tls: # placing a host in the TLS config will determine what ends up in the cert's subjectAltNames\n      - hosts:\n        - lh.gilded.lan # Host to access longhorn\n      # Name of the certifciate (see `kubectl get certificate -A`)\n      secretName: longhorn-tls # cert-manager will store the created certificate in this secret.\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yml",metastring:'title="hab-plays/K3s/charts/longhorn/cert.yml"',title:'"hab-plays/K3s/charts/longhorn/cert.yml"'},'apiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: longhorn-tls\n  namespace: longhorn-system\nspec:\n  # The secret that this cert will be refering to, the secret `longhorn-tls` will contain the private keys for this certificate. The cert manager will create these private keys once this resource definition is applied to k8s.\n  secretName: longhorn-tls\n  # The domain name that this cert will apply to\n  dnsNames:\n    - "lh.gilded.lan"\n  # The authority who will be signing the cert, this was defined earlier when we installed the cert manager.\n  issuerRef:\n    name: selfsigned-issuer\n')),(0,i.kt)("p",null,"You will also need to add ",(0,i.kt)("inlineCode",{parentName:"p"},"lh.gilded.lan")," (or whatever you edit it to) to your\nDNS resolver in your router. It should resolve to the\n",(0,i.kt)("inlineCode",{parentName:"p"},"nginx-ingress-nginx-controller")," ",(0,i.kt)("inlineCode",{parentName:"p"},"LoadBalancer")," ",(0,i.kt)("inlineCode",{parentName:"p"},"External-IP")," address assigned\n",(0,i.kt)("a",{parentName:"p",href:"/docs/l2-k3s/standup-live#nginx"},"above")," (in our case ",(0,i.kt)("inlineCode",{parentName:"p"},"10.1.0.50"),", for which we\ngot ",(0,i.kt)("inlineCode",{parentName:"p"},"404 Not Found nginx"),")."),(0,i.kt)("p",null,"The upshot to getting this kind of exposure to an ingress this early on is that,\nwell, all the cool visual stuff needs an ingress."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Reserve Amounts")),(0,i.kt)("p",null,'Longhorn automatically reserves a % of your host storage for OS. This is a\nlittle silly when the storage is in the TB range, and the % is in tens. Ansible\nwill change this limit to 32 Gi automatically. If you would like to change it,\nin the UI, under the Node tab, you will see, next to each host a column for\n"Size", in each row there should be a "+32 Gi Reserved". You can also change it\nto whatever you want in the Ansible script.'),(0,i.kt)("p",null,"Once everything is installed, you can confirm everything is running by\nnavigating in a browser to ",(0,i.kt)("inlineCode",{parentName:"p"},"lh.gilded.lan")," (or whatever you changed it to). To\nlog in, you will need the user and password created and stored in Ansible vault\n",(0,i.kt)("inlineCode",{parentName:"p"},"vault-lh-auth-token")," (to get these credentials run\n",(0,i.kt)("inlineCode",{parentName:"p"},"ansible-vault edit vault-lh-auth-token"),")."),(0,i.kt)("p",null,"Once logged in, you should see a list of all your cluster storage resources,\nmake sure they line up with reality, issues here may need to be taken care of on\na per-host basis."),(0,i.kt)("h2",{id:"stand-up-live-k3s"},"Stand-up Live K3s"),(0,i.kt)("p",null,"Double check that you are all set and run the command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"apb K3s/standup-live.yml\n")),(0,i.kt)("p",null,"Did it run without issues? If so, congratulations! You now have a live\nKubernetes cluster capable of:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Hosting highly available frontends"),(0,i.kt)("li",{parentName:"ul"},"Hosting highly available backends"),(0,i.kt)("li",{parentName:"ul"},"Encrypting traffic"),(0,i.kt)("li",{parentName:"ul"},"Self Updating"),(0,i.kt)("li",{parentName:"ul"},"Persisting highly available data")),(0,i.kt)("p",null,"And, importantly,"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Hosting any peer to peer architecture, like a Bitcoin Node, in a highly\navailable capacity.")),(0,i.kt)("p",null,"Which is to say, we now have the cluster in a state where we can begin adding\narbitrary apps, services, and frameworks to the cluster. And there is an\noutlandishly large ecosystem out there: logging, analytics, networking, backup,\nmonitoring, alerting, security, and everything else under the sun."),(0,i.kt)("p",null,"Going forward, we can use both Ansible scripts and Helm install scripts. For\nBitcoin, we will use Helm, as the complication that Ansible abstracts away in\nsetting up the cluster is a bit lost for individual one-off apps until we need\nto install many at once."),(0,i.kt)("p",null,"Before we launch our HAB Bitcoin node (Layer 3), let's quickly run through\ntearing down a live cluster."))}h.isMDXComponent=!0}}]);