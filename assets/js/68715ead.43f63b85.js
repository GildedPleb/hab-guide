"use strict";(self.webpackChunkhab_guide=self.webpackChunkhab_guide||[]).push([[4208],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>c});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),d=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=d(e.components);return a.createElement(s.Provider,{value:t},e.children)},h="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),h=d(n),m=o,c=h["".concat(s,".").concat(m)]||h[m]||p[m]||r;return n?a.createElement(c,i(i({ref:t},u),{},{components:n})):a.createElement(c,i({ref:t},u))}));function c(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[h]="string"==typeof e?e:o,i[1]=l;for(var d=2;d<r;d++)i[d]=n[d];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},7760:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>l,toc:()=>d});var a=n(7462),o=(n(7294),n(3905));const r={sidebar_position:3},i="Tear-down Vanilla",l={unversionedId:"l2-k3s/teardown-vanilla",id:"l2-k3s/teardown-vanilla",title:"Tear-down Vanilla",description:"Let's now walk through the process of tearing down a vanilla k3s cluster and",source:"@site/docs/l2-k3s/teardown-vanilla.md",sourceDirName:"l2-k3s",slug:"/l2-k3s/teardown-vanilla",permalink:"/hab-guide/docs/l2-k3s/teardown-vanilla",draft:!1,editUrl:"https://github.com/GildedPleb/hab-guide/edit/master/docs/l2-k3s/teardown-vanilla.md",tags:[],version:"current",lastUpdatedBy:"GildedPleb",lastUpdatedAt:1675810955,formattedLastUpdatedAt:"Feb 7, 2023",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Stand-up Vanilla",permalink:"/hab-guide/docs/l2-k3s/standup-vanilla"},next:{title:"Stand-up Live",permalink:"/hab-guide/docs/l2-k3s/standup-live"}},s={},d=[{value:"Tear It Down",id:"tear-it-down",level:2},{value:"What is the Teardown Command Doing?",id:"what-is-the-teardown-command-doing",level:2},{value:"Implications",id:"implications",level:2}],u={toc:d};function h(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"tear-down-vanilla"},"Tear-down Vanilla"),(0,o.kt)("p",null,"Let's now walk through the process of tearing down a vanilla k3s cluster and\nindividual host."),(0,o.kt)("h2",{id:"tear-it-down"},"Tear It Down"),(0,o.kt)("p",null,"If you would like, you now have the option to tear-down the entire vanilla k3s\ncluster by running:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"apb K3s/teardown-vanilla.yml\n")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"This will not change any hosts, and still keep them in the live state, but it\nwill tear down k3s. So if you run ",(0,o.kt)("inlineCode",{parentName:"li"},"kubectl get nodes -o wide")," again, you will\nget an error."),(0,o.kt)("li",{parentName:"ul"},"If you do not plan on changing the host plan, you can use this to bounce k3s,\nit will also reboot the hosts."),(0,o.kt)("li",{parentName:"ul"},"If you plan on changing the host plan, you should also tear down the live\nhosts.")),(0,o.kt)("p",null,"However, it has been a part of the plan from the outset to be able to trivially\nremove hosts willy-nilly."),(0,o.kt)("p",null,"You can now also run this command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'apb K3s/teardown-live.yml -e "killhosts=pi4,pi5"\n')),(0,o.kt)("p",null,"This will safely remove a host by name (separated by commas if more than one).\nIn this case, ",(0,o.kt)("inlineCode",{parentName:"p"},"killhosts=pi4,pi5")," are to be removed from the Kubernetes cluster\nand have k3s uninstalled from them, only. They will be returned to the live host\nstate and are ready to be brought back into the cluster if need be."),(0,o.kt)("admonition",{type:"info"},(0,o.kt)("p",{parentName:"admonition"},"As of the time of writing (Dec 2022) there appears to be\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/k3s-io/k3s/issues/4023"},"a bug")," which may cause a master host\nto rejoin if you try to remove him. We'd just not intentionally remove\nindividual master hosts for the time being... If you want to tear-down a master\nhost, and you have 3 master hosts, you should tear-down the entire cluster, if\nyou have more, like 5 or 7, you should only tear them down two at a time to\nmaintain an odd quorum.")),(0,o.kt)("h2",{id:"what-is-the-teardown-command-doing"},"What is the Teardown Command Doing?"),(0,o.kt)("p",null,"You should notice a new and strange command now entering the Ansible landscape:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash",metastring:'title="hab-plays/K3s/teardown-vanilla.yml"',title:'"hab-plays/K3s/teardown-vanilla.yml"'},'...\n    - name: Drain Node before terminating\n      when: killhosts is defined\n      kubernetes.core.k8s_drain:\n        state: drain\n        name: "{{ item }}"\n        delete_options:\n          wait_timeout: 0\n          wait_sleep: 5\n          ignore_daemonsets: yes\n          disable_eviction: yes\n          terminate_grace_period: 5\n          force: yes\n      loop: "{{ killhosts.split(\',\') }}"\n      failed_when: false\n    - name: Delete Node\n      when: killhosts is defined\n      kubernetes.core.k8s:\n        api_version: v1\n        name: "{{ item }}"\n        kind: Node\n        state: absent\n      loop: "{{ killhosts.split(\',\') }}"\n...\n')),(0,o.kt)("p",null,"In particular, this bit ",(0,o.kt)("inlineCode",{parentName:"p"},"kubernetes.core..."),". This is Ansible calling its\nKubernetes package. You'll see this pattern frequently going forward. Because\nAnsible and Kubernetes both use ",(0,o.kt)("inlineCode",{parentName:"p"},"yml")," formatting to interpret what we want them\nto do, we can seamlessly move from an Ansible setting to a Kubernetes one. In\nthe above block, the ",(0,o.kt)("inlineCode",{parentName:"p"},"Drain Node before terminating")," task is a fairly\nwell-defined k8s task for a host, so it comes with presets. Moving forward, you\nwill also see a ",(0,o.kt)("inlineCode",{parentName:"p"},"definition")," key after ",(0,o.kt)("inlineCode",{parentName:"p"},"kubernetes.core")," which is actually a\npure k8s resource definition, such that you wouldn't even need Ansible to add it\nto k8s (you could simply use ",(0,o.kt)("inlineCode",{parentName:"p"},"kubectl apply -f resource.yml"),"). At that point, we\ncontinue to use Ansible to make sure we are idempotent and thorough."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"What is ",(0,o.kt)("inlineCode",{parentName:"strong"},"Drain Node...")," doing?")," If ",(0,o.kt)("inlineCode",{parentName:"li"},"killhosts")," is set, Drain is moving\n",(0,o.kt)("em",{parentName:"li"},"all")," the resources and pods off the hosts and making sure they are working\nproperly on other hosts. This makes sense, obviously, because we are removing\nthe host from the cluster."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"What is ",(0,o.kt)("inlineCode",{parentName:"strong"},"Delete Node")," doing?")," If ",(0,o.kt)("inlineCode",{parentName:"li"},"killhosts")," is set, by setting the\n",(0,o.kt)("inlineCode",{parentName:"li"},"kind: Node")," resource to a ",(0,o.kt)("inlineCode",{parentName:"li"},"absent")," state we are telling Kubernetes to no\nlonger retain the resource with name ",(0,o.kt)("inlineCode",{parentName:"li"},"{{ item from killhost list }}")," in the\ncluster. Bye bye host.")),(0,o.kt)("admonition",{type:"caution"},(0,o.kt)("p",{parentName:"admonition"},"When you remove a host, k3s transfers resources to other nodes. As such, you\nshould avoid removing hosts if you can not absorb the work load and storage\nrequirements on remaining hosts. Further, this might take a long time with a\nheavy host load.")),(0,o.kt)("h2",{id:"implications"},"Implications"),(0,o.kt)("p",null,"If you want to re-add these hosts, you will need to add them back into the\ncluster as they were previously defined, unless you also change the host-plan,\nwhich might mean also needing to tear down the entire cluster."),(0,o.kt)("p",null,'All vanilla+-k3s-live-hosts can not be changed at the vanilla host level without\nfirst bringing them down to the vanilla host state. To re-org the cluster, you\nmust either tear everything down, and re-build all-at-once, or you must do it\nincrementally, host-by-host. It can not be done, declarative, "on-the-fly", but,\nperhaps one day.'),(0,o.kt)("p",null,"Fool around with your node plan, and take a moment to appreciate your cluster.\nIt's truly hard to overstate the level of complexity which is taking place as\nyou watch your node build layers of abstraction that support further layers of\nabstraction. And not from our Ansible scripts, but from standing on the\nshoulders of giants that this is built on."),(0,o.kt)("admonition",{title:"Advanced HAB node exercise",type:"tip"},(0,o.kt)("p",{parentName:"admonition"},"Given 3 master hosts and at least 4 workers, tear down two worker hosts, and\nstand them up as master hosts, then tear down two previous master hosts and\nstand them up as worker hosts, repeat this until you have fully cycled all\nmaster hosts."),(0,o.kt)("p",{parentName:"admonition"},"Is your cluster still operational?")),(0,o.kt)("p",null,"Comfortable? Let's prepare Kubernetes to be warm and welcoming for Bitcoin."))}h.isMDXComponent=!0}}]);